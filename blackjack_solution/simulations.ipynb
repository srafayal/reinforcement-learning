{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "from lib import policies\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions: hit or stand\n",
    "ACTION_HIT = 0\n",
    "ACTION_STAND = 1  #  \"strike\" \n",
    "ACTIONS = [ACTION_HIT, ACTION_STAND]\n",
    "\n",
    "def banchmark_policy():\n",
    "    def policy_fn(state,Q_vals ):\n",
    "        player_sum =state[0]\n",
    "        return ACTION_HIT if player_sum<17 else ACTION_STAND\n",
    "    return policy_fn\n",
    "\n",
    "\n",
    "def dealer_policy(dealer_sum):\n",
    "    return ACTION_HIT if dealer_sum<17 else ACTION_STAND\n",
    "# get a new card\n",
    "def get_card():\n",
    "    card = np.random.randint(1, 14)\n",
    "    return  card ,11 if card == 1 else min(card, 10)\n",
    "\n",
    "\n",
    "def load( name):\n",
    "    Q_vals = pd.read_pickle(name)\n",
    "    return Q_vals\n",
    "\n",
    "def model_Q_vals( action_size):\n",
    "\n",
    "    def policy_fn(state,Q_vals  ): \n",
    "#         print( state )\n",
    "#         print( list(Q_vals[ state ].values()) )\n",
    "        best_action = np.argmax(list(Q_vals[ state ].values()))\n",
    "#         print(best_action)\n",
    "        return best_action\n",
    "    \n",
    "    return policy_fn\n",
    "\n",
    "def make_epsilon_greedy_policy(estimator, nA):\n",
    "\n",
    "    def policy_fn(  state,Q_vals):\n",
    "        s =[]\n",
    "        s.append(  state)  \n",
    "        q_values = estimator.predict(np.array(s )) \n",
    "        best_action = np.argmax(q_values)\n",
    "        \n",
    "        return best_action\n",
    "    return policy_fn\n",
    "\n",
    "\n",
    "def play( player_sum, dealer_sum,player_ace,policy_player, Q_vals=None ):\n",
    " \n",
    "   \n",
    "    #print(dealer_cards['card_name'].iloc[0] )\n",
    "    #print(dealer_cards)\n",
    "    #player_ace =    player_cards[player_cards.card_name== 1]\n",
    "    \n",
    "    \n",
    "    #state = [usable_ace_player, player_sum, dealer_card1]\n",
    "\n",
    "    \n",
    "#     banchmark_reward = 0\n",
    "    player_reward =0\n",
    "    \n",
    "#     banchmark_player_sum = player_sum\n",
    "    # player's turn\n",
    "    while True:\n",
    "        # get action based on current sum\n",
    "        state = (player_sum, dealer_sum,player_ace)\n",
    "        action = policy_player(state,Q_vals)\n",
    "\n",
    "         \n",
    "        if action == ACTION_STAND:\n",
    "            break\n",
    "        # if hit, get new card\n",
    "        card, new_card_value = get_card()\n",
    "         \n",
    "        \n",
    "        # Keep track of the ace count. the usable_ace_player flag is insufficient alone as it cannot\n",
    "        # distinguish between having one ace or two.\n",
    "        if card==1:\n",
    "            player_ace=True\n",
    "            if (player_sum+new_card_value) > 21:\n",
    "                new_card_value=1\n",
    "        \n",
    "        player_sum = player_sum+new_card_value\n",
    "#         if banchmark_player_sum<17:\n",
    "#             banchmark_player_sum=player_sum\n",
    "            \n",
    "\n",
    "#         # player busts\n",
    "        if player_sum > 21:\n",
    "            player_reward= -1\n",
    "            break\n",
    " \n",
    "        \n",
    "\n",
    "    # dealer's turn\n",
    "    while True:\n",
    "        # get action based on current sum\n",
    "        action = dealer_policy(dealer_sum)\n",
    "        \n",
    "        if action == ACTION_STAND:\n",
    "            break\n",
    "            \n",
    "        # if hit, get a new card     \n",
    "        dealer_card, new_card_value  = get_card()\n",
    "        #new_card = {'card_name':dealer_card, 'value':new_card_value}\n",
    "        #dealer_cards = dealer_cards.append(new_card, ignore_index=True)\n",
    "        if dealer_card==1:\n",
    "            ace = True#   dealer_cards[dealer_cards.card_name== 1] \n",
    "        \n",
    "        # If the dealer has a usable ace, use it as 1 to avoid busting and continue.\n",
    "        if dealer_card==1:\n",
    "            if (dealer_sum + new_card_value) > 21 and ace== True:\n",
    "                new_card_value=1\n",
    "        \n",
    "        dealer_sum = dealer_sum + new_card_value\n",
    "        # dealer busts\n",
    "        #dealer_sum = sum(dealer_cards['value'])\n",
    "        if dealer_sum > 21:\n",
    "            player_reward=1\n",
    " \n",
    "            return  player_reward  \n",
    "\n",
    "    \n",
    "    # Reward Calculation\n",
    "#     print(\"P:{},D:{},B:{}\".format(player_sum,dealer_sum,banchmark_player_sum))\n",
    "#     print(\"d:{}\".format(dealer_sum))\n",
    "#     assert player_sum <= 21 and dealer_sum <= 21\n",
    "    if player_reward!=-1:\n",
    "        if player_sum > dealer_sum:\n",
    "            player_reward=  1 \n",
    "        elif player_sum == dealer_sum:\n",
    "            player_reward=  0 \n",
    "        else:\n",
    "            player_reward=  -1 \n",
    "\n",
    "#     if banchmark_player_sum > dealer_sum:\n",
    "#         banchmark_reward=  1 \n",
    "#     elif banchmark_player_sum == dealer_sum:\n",
    "#         banchmark_reward=  0 \n",
    "#     else:\n",
    "#         banchmark_reward=  -1 \n",
    "    \n",
    "    return  player_reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_MC_off_vals_50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [(p_sum, d_sum, ace) for ace in  (True,False) for p_sum in range(12,22) for d_sum in range(1,13)]\n",
    "#all_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q=load('model_output/final_MC_off_vals_100K.pkl')\n",
    "# r=play(19, 7, False, current_policy,Q)\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(Q,name):\n",
    "    win=0\n",
    "    loss=0\n",
    "    draw=0\n",
    "\n",
    "\n",
    "\n",
    "    b_win=0\n",
    "    b_loss=0\n",
    "    b_draw=0\n",
    "\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    for st in all_states:\n",
    "        player_reward=play(st[0], st[1], st[2], current_policy,Q)\n",
    "        if player_reward==1:\n",
    "            win=win+1\n",
    "        elif player_reward==-1:\n",
    "            loss=loss+1\n",
    "        else:\n",
    "            draw=draw+1\n",
    "\n",
    "#         if banchmark_reward==1:\n",
    "#             b_win=b_win+1\n",
    "#         elif banchmark_reward==-1:\n",
    "#             b_loss=b_loss+1\n",
    "#         else:\n",
    "#             b_draw=b_draw+1\n",
    "    print(\"Name:{}---Agent---win:{},loss:{}, draw:{}\".format(name, win, loss, draw))\n",
    "#     print(\"Name:{}---Benchmark---win:{},loss:{}, draw:{}\".format(name, b_win, b_loss, b_draw))\n",
    "    \n",
    "    return win/len(all_states),b_win/len(all_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:banchmark---Agent---win:123,loss:96, draw:21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5125, 0.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_policy= banchmark_policy(  )\n",
    "run_simulation(None,'banchmark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_policy= model_Q_vals( 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:MC_off---Agent---win:127,loss:95, draw:18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5291666666666667, 0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=load('model_output/final_MC_off_vals_50K.pkl')\n",
    "run_simulation(Q,'MC_off')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynaQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:DynaQ---Agent---win:117,loss:93, draw:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4875, 0.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=load('model_output/final_DynaQ_vals.pkl')\n",
    "run_simulation(Q,'DynaQ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:QLearning---Agent---win:121,loss:109, draw:10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5041666666666667, 0.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=load('model_output/final_QLearning_50K.pkl')\n",
    "run_simulation(Q,'QLearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dqn.DQNAgent(500,32,\"model_output/\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load(\"model_output/final_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:DQN---Agent---win:117,loss:93, draw:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4875, 0.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_policy=make_epsilon_greedy_policy(agent.q_estimator,2)\n",
    "run_simulation(None,'DQN')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "np.random.randint(1, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
